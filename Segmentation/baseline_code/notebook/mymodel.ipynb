{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#하이퍼파라미터-세팅-및-seed-고정\" data-toc-modified-id=\"하이퍼파라미터-세팅-및-seed-고정-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>하이퍼파라미터 세팅 및 seed 고정</a></span></li><li><span><a href=\"#학습-데이터-EDA\" data-toc-modified-id=\"학습-데이터-EDA-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>학습 데이터 EDA</a></span></li><li><span><a href=\"#데이터-전처리-함수-정의-(Dataset)\" data-toc-modified-id=\"데이터-전처리-함수-정의-(Dataset)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>데이터 전처리 함수 정의 (Dataset)</a></span></li><li><span><a href=\"#Dataset-정의-및-DataLoader-할당\" data-toc-modified-id=\"Dataset-정의-및-DataLoader-할당-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Dataset 정의 및 DataLoader 할당</a></span><ul class=\"toc-item\"><li><span><a href=\"#데이터-샘플-시각화-(Show-example-image-and-mask)\" data-toc-modified-id=\"데이터-샘플-시각화-(Show-example-image-and-mask)-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>데이터 샘플 시각화 (Show example image and mask)</a></span></li></ul></li><li><span><a href=\"#baseline-model\" data-toc-modified-id=\"baseline-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>baseline model</a></span><ul class=\"toc-item\"><li><span><a href=\"#FCN8s-(VGG-imageNet-weight)\" data-toc-modified-id=\"FCN8s-(VGG-imageNet-weight)-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>FCN8s (VGG imageNet weight)</a></span></li></ul></li><li><span><a href=\"#train,-validation,-test-함수-정의\" data-toc-modified-id=\"train,-validation,-test-함수-정의-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>train, validation, test 함수 정의</a></span></li><li><span><a href=\"#모델-저장-함수-정의\" data-toc-modified-id=\"모델-저장-함수-정의-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>모델 저장 함수 정의</a></span></li><li><span><a href=\"#모델-생성-및-Loss-function,-Optimizer-정의\" data-toc-modified-id=\"모델-생성-및-Loss-function,-Optimizer-정의-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>모델 생성 및 Loss function, Optimizer 정의</a></span></li><li><span><a href=\"#저장된-model-불러오기-(학습된-이후)\" data-toc-modified-id=\"저장된-model-불러오기-(학습된-이후)-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>저장된 model 불러오기 (학습된 이후)</a></span></li><li><span><a href=\"#submission을-위한-test-함수-정의\" data-toc-modified-id=\"submission을-위한-test-함수-정의-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>submission을 위한 test 함수 정의</a></span></li><li><span><a href=\"#submission.csv-생성\" data-toc-modified-id=\"submission.csv-생성-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>submission.csv 생성</a></span></li><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay          48G   21G   25G  46% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "tmpfs            45G     0   45G   0% /sys/fs/cgroup\n",
      "shm             1.0G     0  1.0G   0% /dev/shm\n",
      "/dev/xvda1       48G   21G   25G  46% /etc/hosts\n",
      "tmpfs            45G   12K   45G   1% /proc/driver/nvidia\n",
      "udev             45G     0   45G   0% /dev/nvidia0\n",
      "tmpfs            45G     0   45G   0% /proc/acpi\n",
      "tmpfs            45G     0   45G   0% /proc/scsi\n",
      "tmpfs            45G     0   45G   0% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:06:58.944902Z",
     "start_time": "2021-04-22T11:06:56.623974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.7.1+cu101\n",
      "GPU 사용 가능 여부: True\n",
      "Tesla V100-PCIE-32GB\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import label_accuracy_score\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 전처리를 위한 라이브러리\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "plt.rcParams['axes.grid'] = False\n",
    "\n",
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"   # GPU 사용 가능 여부에 따라 device 정보 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 세팅 및 seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:06:59.171980Z",
     "start_time": "2021-04-22T11:06:59.167952Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16   # Mini-batch size\n",
    "num_epochs = 30\n",
    "learning_rate = 0.0001\n",
    "early_stopping_count = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:06:59.446510Z",
     "start_time": "2021-04-22T11:06:59.443508Z"
    }
   },
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 0\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "# torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:07:04.139668Z",
     "start_time": "2021-04-22T11:07:00.575728Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of super categories: 11\n",
      "Number of categories: 11\n",
      "Number of annotations: 21116\n",
      "Number of images: 2617\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "dataset_path = '../input/data'\n",
    "anns_file_path = dataset_path + '/' + 'train.json'\n",
    "\n",
    "# Read annotations\n",
    "with open(anns_file_path, 'r') as f:\n",
    "    dataset = json.loads(f.read())\n",
    "\n",
    "categories = dataset['categories']\n",
    "anns = dataset['annotations']\n",
    "imgs = dataset['images']\n",
    "nr_cats = len(categories)\n",
    "nr_annotations = len(anns)\n",
    "nr_images = len(imgs)\n",
    "\n",
    "# Load categories and super categories\n",
    "cat_names = []\n",
    "super_cat_names = []\n",
    "super_cat_ids = {}\n",
    "super_cat_last_name = ''\n",
    "nr_super_cats = 0\n",
    "for cat_it in categories:\n",
    "    cat_names.append(cat_it['name'])\n",
    "    super_cat_name = cat_it['supercategory']\n",
    "    # Adding new supercat\n",
    "    if super_cat_name != super_cat_last_name:\n",
    "        super_cat_names.append(super_cat_name)\n",
    "        super_cat_ids[super_cat_name] = nr_super_cats\n",
    "        super_cat_last_name = super_cat_name\n",
    "        nr_super_cats += 1\n",
    "\n",
    "print('Number of super categories:', nr_super_cats)\n",
    "print('Number of categories:', nr_cats)\n",
    "print('Number of annotations:', nr_annotations)\n",
    "print('Number of images:', nr_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:07:04.394832Z",
     "start_time": "2021-04-22T11:07:04.141668Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count annotations\n",
    "cat_histogram = np.zeros(nr_cats,dtype=int)\n",
    "for ann in anns:\n",
    "    cat_histogram[ann['category_id']] += 1\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({'Categories': cat_names, 'Number of annotations': cat_histogram})\n",
    "df = df.sort_values('Number of annotations', 0, False)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.title(\"category distribution of train set \")\n",
    "plot_1 = sns.barplot(x=\"Number of annotations\", y=\"Categories\", data=df, label=\"Total\", color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:07:04.409808Z",
     "start_time": "2021-04-22T11:07:04.395831Z"
    }
   },
   "outputs": [],
   "source": [
    "# category labeling \n",
    "sorted_temp_df = df.sort_index()\n",
    "\n",
    "# background = 0 에 해당되는 label 추가 후 기존들을 모두 label + 1 로 설정\n",
    "sorted_df = pd.DataFrame([\"Backgroud\"], columns = [\"Categories\"])\n",
    "sorted_df = sorted_df.append(sorted_temp_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:07:04.424832Z",
     "start_time": "2021-04-22T11:07:04.411802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categories</th>\n",
       "      <th>Number of annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backgroud</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>General trash</td>\n",
       "      <td>2225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paper</td>\n",
       "      <td>7448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paper pack</td>\n",
       "      <td>527.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Metal</td>\n",
       "      <td>449.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Glass</td>\n",
       "      <td>488.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Plastic</td>\n",
       "      <td>2472.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Styrofoam</td>\n",
       "      <td>1074.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Plastic bag</td>\n",
       "      <td>6114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Battery</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Clothing</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Categories  Number of annotations\n",
       "0       Backgroud                    NaN\n",
       "1         UNKNOWN                  128.0\n",
       "2   General trash                 2225.0\n",
       "3           Paper                 7448.0\n",
       "4      Paper pack                  527.0\n",
       "5           Metal                  449.0\n",
       "6           Glass                  488.0\n",
       "7         Plastic                 2472.0\n",
       "8       Styrofoam                 1074.0\n",
       "9     Plastic bag                 6114.0\n",
       "10        Battery                   50.0\n",
       "11       Clothing                  141.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class (Categories) 에 따른 index 확인 (0~11 : 총 12개)\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 함수 정의 (Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:07:04.439837Z",
     "start_time": "2021-04-22T11:07:04.425804Z"
    }
   },
   "outputs": [],
   "source": [
    "category_names = list(sorted_df.Categories)\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\"\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"COCO format\"\"\"\n",
    "    def __init__(self, data_dir, mode = 'train', transform = None):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.coco = COCO(data_dir)\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        images = cv2.imread(os.path.join(dataset_path, image_infos['file_name']))\n",
    "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        images /= 255.0\n",
    "        \n",
    "        if (self.mode in ('train', 'val')):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            # Load the categories in a variable\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id + 1\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            # Unknown = 1, General trash = 2, ... , Cigarette = 11\n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i]['category_id'], cats)\n",
    "                pixel_value = category_names.index(className)\n",
    "                masks = np.maximum(self.coco.annToMask(anns[i])*pixel_value, masks)\n",
    "            masks = masks.astype(np.float32)\n",
    "\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "            \n",
    "            return images, masks, image_infos\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "            \n",
    "            return images, image_infos\n",
    "    \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 정의 및 DataLoader 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:07:09.179806Z",
     "start_time": "2021-04-22T11:07:04.440804Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=3.66s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=1.46s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# train.json / validation.json / test.json 디렉토리 설정\n",
    "train_path = dataset_path + '/train.json'\n",
    "val_path = dataset_path + '/val.json'\n",
    "test_path = dataset_path + '/test.json'\n",
    "\n",
    "# collate_fn needs for batch\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    \n",
    "    ToTensorV2(),    \n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    \n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    \n",
    "    ToTensorV2(),       \n",
    "])\n",
    "\n",
    "# create own Dataset 1 (skip)\n",
    "# validation set을 직접 나누고 싶은 경우\n",
    "# random_split 사용하여 data set을 8:2 로 분할\n",
    "# train_size = int(0.8*len(dataset))\n",
    "# val_size = int(len(dataset)-train_size)\n",
    "# dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=transform)\n",
    "# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# create own Dataset 2\n",
    "# train dataset\n",
    "train_dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=train_transform)\n",
    "\n",
    "# validation dataset\n",
    "val_dataset = CustomDataLoader(data_dir=val_path, mode='val', transform=val_transform)\n",
    "\n",
    "# test dataset\n",
    "test_dataset = CustomDataLoader(data_dir=test_path, mode='test', transform=test_transform)\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=4,\n",
    "                                           collate_fn=collate_fn)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=4,\n",
    "                                         collate_fn=collate_fn)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          num_workers=4,\n",
    "                                          collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 샘플 시각화 (Show example image and mask)\n",
    "\n",
    "- `train_loader` \n",
    "- `val_loader` \n",
    "- `test_loader` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:07:09.779805Z",
     "start_time": "2021-04-22T11:07:09.181803Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_loader의 output 결과(image 및 mask) 확인\n",
    "for imgs, masks, image_infos in train_loader:\n",
    "    image_infos = image_infos[0]\n",
    "    temp_images = imgs\n",
    "    temp_masks = masks\n",
    "    \n",
    "    break\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 12))\n",
    "\n",
    "print('image shape:', list(temp_images[0].shape))\n",
    "print('mask shape: ', list(temp_masks[0].shape))\n",
    "print('Unique values, category of transformed mask : \\n', [{int(i),category_names[int(i)]} for i in list(np.unique(temp_masks[0]))])\n",
    "\n",
    "ax1.imshow(temp_images[0].permute([1,2,0]))\n",
    "ax1.grid(False)\n",
    "ax1.set_title(\"input image : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "ax2.imshow(temp_masks[0])\n",
    "ax2.grid(False)\n",
    "ax2.set_title(\"masks : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:07:10.469862Z",
     "start_time": "2021-04-22T11:07:09.780831Z"
    }
   },
   "outputs": [],
   "source": [
    "# val_loader의 output 결과(image 및 mask) 확인\n",
    "for imgs, masks, image_infos in val_loader:\n",
    "    image_infos = image_infos[0]\n",
    "    temp_images = imgs\n",
    "    temp_masks = masks\n",
    "    \n",
    "    break\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 12))\n",
    "\n",
    "print('image shape:', list(temp_images[0].shape))\n",
    "print('mask shape: ', list(temp_masks[0].shape))\n",
    "\n",
    "print('Unique values, category of transformed mask : \\n', [{int(i),category_names[int(i)]} for i in list(np.unique(temp_masks[0]))])\n",
    "\n",
    "ax1.imshow(temp_images[0].permute([1,2,0]))\n",
    "ax1.grid(False)\n",
    "ax1.set_title(\"input image : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "ax2.imshow(temp_masks[0])\n",
    "ax2.grid(False)\n",
    "ax2.set_title(\"masks : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:07:10.772294Z",
     "start_time": "2021-04-22T11:07:10.470862Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_loader의 output 결과(image) 확인\n",
    "for imgs, image_infos in test_loader:\n",
    "    image_infos = image_infos[0]\n",
    "    temp_images = imgs\n",
    "    \n",
    "    break\n",
    "\n",
    "fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "\n",
    "print('image shape:', list(temp_images[0].shape))\n",
    "\n",
    "ax1.imshow(temp_images[0].permute([1,2,0]))\n",
    "ax1.grid(False)\n",
    "ax1.set_title(\"input image : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline model\n",
    "\n",
    "### FCN8s (VGG imageNet weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:15:29.119807Z",
     "start_time": "2021-04-22T11:15:29.109808Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision.models import vgg16\n",
    "\n",
    "class FCN8s(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(FCN8s,self).__init__()\n",
    "        self.pretrained_model = vgg16(pretrained = True)\n",
    "        features, classifiers = list(self.pretrained_model.features.children()), list(self.pretrained_model.classifier.children())\n",
    "\n",
    "        self.features_map1 = nn.Sequential(*features[0:17])\n",
    "        self.features_map2 = nn.Sequential(*features[17:24])\n",
    "        self.features_map3 = nn.Sequential(*features[24:31])\n",
    "        \n",
    "        # Score pool3\n",
    "        self.score_pool3_fr = nn.Conv2d(256, num_classes, 1)\n",
    "        \n",
    "        # Score pool4        \n",
    "        self.score_pool4_fr = nn.Conv2d(512, num_classes, 1)        \n",
    "        \n",
    "        # fc6 ~ fc7\n",
    "        self.conv = nn.Sequential(nn.Conv2d(512, 4096, kernel_size = 1),\n",
    "                                  nn.ReLU(inplace=True),\n",
    "                                  nn.Dropout(),\n",
    "                                  nn.Conv2d(4096, 4096, kernel_size = 1),\n",
    "                                  nn.ReLU(inplace=True),\n",
    "                                  nn.Dropout()\n",
    "                                  )\n",
    "        \n",
    "        # Score\n",
    "        self.score_fr = nn.Conv2d(4096, num_classes, kernel_size = 1)\n",
    "        \n",
    "        # UpScore2 using deconv\n",
    "        self.upscore2 = nn.ConvTranspose2d(num_classes,\n",
    "                                           num_classes,\n",
    "                                           kernel_size=4,\n",
    "                                           stride=2,\n",
    "                                           padding=1)\n",
    "        \n",
    "        # UpScore2_pool4 using deconv\n",
    "        self.upscore2_pool4 = nn.ConvTranspose2d(num_classes, \n",
    "                                                 num_classes, \n",
    "                                                 kernel_size=4,\n",
    "                                                 stride=2,\n",
    "                                                 padding=1)\n",
    "        \n",
    "        # UpScore8 using deconv\n",
    "        self.upscore8 = nn.ConvTranspose2d(num_classes, \n",
    "                                           num_classes,\n",
    "                                           kernel_size=16,\n",
    "                                           stride=8,\n",
    "                                           padding=4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pool3 = h = self.features_map1(x)\n",
    "        pool4 = h = self.features_map2(h)\n",
    "        h = self.features_map3(h)\n",
    "        \n",
    "        h = self.conv(h)\n",
    "        h = self.score_fr(h)\n",
    "       \n",
    "        score_pool3c = self.score_pool3_fr(pool3)    \n",
    "        score_pool4c = self.score_pool4_fr(pool4)\n",
    "        \n",
    "        # Up Score I\n",
    "        upscore2 = self.upscore2(h)\n",
    "        \n",
    "        # Sum I\n",
    "        h = upscore2 + score_pool4c\n",
    "        \n",
    "        # Up Score II\n",
    "        upscore2_pool4c = self.upscore2_pool4(h)\n",
    "        \n",
    "        # Sum II\n",
    "        h = upscore2_pool4c + score_pool3c\n",
    "        \n",
    "        # Up Score III\n",
    "        upscore8 = self.upscore8(h)\n",
    "        \n",
    "        return upscore8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "\n",
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name='efficientnet-b0',\n",
    "    encoder_weights='imagenet',\n",
    "    in_channels=3,\n",
    "    classes=12,\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:15:34.624277Z",
     "start_time": "2021-04-22T11:15:30.068347Z"
    }
   },
   "outputs": [],
   "source": [
    "# # 구현된 model에 임의의 input을 넣어 output이 잘 나오는지 test\n",
    "\n",
    "\n",
    "\n",
    "# x = torch.randn([1, 3, 512, 512])\n",
    "# print(\"input shape : \", x.shape)\n",
    "# out = model(x).to(device)\n",
    "# print(\"output shape : \", out.size())\n",
    "\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, validation, test 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:15:38.201874Z",
     "start_time": "2021-04-22T11:15:38.187884Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(num_epochs, model, data_loader, val_loader, criterion, optimizer, saved_dir, val_every, device):\n",
    "    print('Start training..')\n",
    "    best_loss = 9999999\n",
    "    stop_count = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        since = time.time()\n",
    "        model.train()\n",
    "        \n",
    "        for step, (images, masks, _) in enumerate(data_loader):\n",
    "            \n",
    "            images = torch.stack(images)       # (batch, channel, height, width)\n",
    "            masks = torch.stack(masks).long()  # (batch, channel, height, width)\n",
    "            \n",
    "            # gpu 연산을 위해 device 할당\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "                  \n",
    "            # inference\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # loss 계산 (cross entropy loss)\n",
    "            loss = criterion(outputs, masks)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # step 주기에 따른 loss 출력\n",
    "            if (step + 1) % 25 == 0:\n",
    "                step_time_elapsed = time.time() - since\n",
    "                \n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Time: {}m {}s'.format(\n",
    "                    epoch+1, num_epochs, step+1, len(train_loader), loss.item(), step_time_elapsed // 60, step_time_elapsed % 60))\n",
    "        \n",
    "        # validation 주기에 따른 loss 출력 및 best model 저장\n",
    "        if (epoch + 1) % val_every == 0:\n",
    "            avrg_loss = validation(epoch + 1, model, val_loader, criterion, device)\n",
    "            if avrg_loss < best_loss:\n",
    "                print('Best performance at epoch: {}'.format(epoch + 1))\n",
    "                print('Save model in', saved_dir)\n",
    "                best_loss = avrg_loss\n",
    "                save_model(model, saved_dir)\n",
    "                stop_count = 0\n",
    "            else:\n",
    "                stop_count += 1\n",
    "        \n",
    "        if stop_count >= early_stopping_count:\n",
    "            print('...Early Stopping...')\n",
    "            print()\n",
    "            break\n",
    "        \n",
    "        ######################## Training Time(epoch) Check ########################\n",
    "        time_elapsed = time.time() - since\n",
    "        print('='*30)\n",
    "        print(f'Training complete in {time_elapsed // 60}m {time_elapsed % 60}s')\n",
    "        print('='*30)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:15:38.901226Z",
     "start_time": "2021-04-22T11:15:38.888195Z"
    }
   },
   "outputs": [],
   "source": [
    "def validation(epoch, model, data_loader, criterion, device):\n",
    "    print('Start validation #{}'.format(epoch))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        cnt = 0\n",
    "        mIoU_list = []\n",
    "        for step, (images, masks, _) in enumerate(data_loader):\n",
    "            \n",
    "            images = torch.stack(images)       # (batch, channel, height, width)\n",
    "            masks = torch.stack(masks).long()  # (batch, channel, height, width)\n",
    "\n",
    "            images, masks = images.to(device), masks.to(device)            \n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            total_loss += loss\n",
    "            cnt += 1\n",
    "            \n",
    "            outputs = torch.argmax(outputs.squeeze(), dim=1).detach().cpu().numpy()\n",
    "\n",
    "            mIoU = label_accuracy_score(masks.detach().cpu().numpy(), outputs, n_class=12)[2]\n",
    "            mIoU_list.append(mIoU)\n",
    "            \n",
    "        avrg_loss = total_loss / cnt\n",
    "        print('Validation #{}  Average Loss: {:.4f}, mIoU: {:.4f}'.format(epoch, avrg_loss, np.mean(mIoU_list)))\n",
    "\n",
    "    return avrg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:15:41.634492Z",
     "start_time": "2021-04-22T11:15:41.627493Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 저장 함수 정의\n",
    "val_every = 1 \n",
    "\n",
    "saved_dir = './saved'\n",
    "if not os.path.isdir(saved_dir):                                                           \n",
    "    os.mkdir(saved_dir)\n",
    "    \n",
    "def save_model(model, saved_dir, file_name='best_model(pretrained).pt'):\n",
    "    check_point = {'net': model.state_dict()}\n",
    "    output_path = os.path.join(saved_dir, file_name)\n",
    "    torch.save(model.state_dict(), output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성 및 Loss function, Optimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:15:43.106368Z",
     "start_time": "2021-04-22T11:15:43.096368Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loss function 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer 정의\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-04-22T11:15:43.700Z"
    }
   },
   "outputs": [],
   "source": [
    "train(num_epochs, model, train_loader, val_loader, criterion, optimizer, saved_dir, val_every, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 저장된 model 불러오기 (학습된 이후) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T19:44:21.050200Z",
     "start_time": "2021-04-16T19:44:20.802200Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# best model 저장된 경로\n",
    "model_path = './saved/best_model(pretrained).pt'\n",
    "\n",
    "# best model 불러오기\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# 추론을 실행하기 전에는 반드시 설정 (batch normalization, dropout 를 평가 모드로 설정)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T19:44:24.939227Z",
     "start_time": "2021-04-16T19:44:24.518228Z"
    }
   },
   "outputs": [],
   "source": [
    "# 첫번째 batch의 추론 결과 확인\n",
    "for imgs, image_infos in test_loader:\n",
    "    image_infos = image_infos\n",
    "    temp_images = imgs\n",
    "    \n",
    "    model.eval()\n",
    "    # inference\n",
    "    outs = model(torch.stack(temp_images).to(device))\n",
    "    oms = torch.argmax(outs.squeeze(), dim=1).detach().cpu().numpy()\n",
    "    \n",
    "    break\n",
    "\n",
    "i = 3\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\n",
    "\n",
    "print('Shape of Original Image :', list(temp_images[i].shape))\n",
    "print('Shape of Predicted : ', list(oms[i].shape))\n",
    "print('Unique values, category of transformed mask : \\n', [{int(i),category_names[int(i)]} for i in list(np.unique(oms[i]))])\n",
    "\n",
    "# Original image\n",
    "ax1.imshow(temp_images[i].permute([1,2,0]))\n",
    "ax1.grid(False)\n",
    "ax1.set_title(\"Original image : {}\".format(image_infos[i]['file_name']), fontsize = 15)\n",
    "\n",
    "# Predicted\n",
    "ax2.imshow(oms[i])\n",
    "ax2.grid(False)\n",
    "ax2.set_title(\"Predicted : {}\".format(image_infos[i]['file_name']), fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submission을 위한 test 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T19:44:27.469285Z",
     "start_time": "2021-04-16T19:44:27.456021Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    size = 256\n",
    "    transform = A.Compose([A.Resize(256, 256)])\n",
    "    print('Start prediction.')\n",
    "    model.eval()\n",
    "    \n",
    "    file_name_list = []\n",
    "    preds_array = np.empty((0, size*size), dtype=np.long)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, (imgs, image_infos) in enumerate(test_loader):\n",
    "\n",
    "            # inference (512 x 512)\n",
    "            outs = model(torch.stack(imgs).to(device))\n",
    "            oms = torch.argmax(outs.squeeze(), dim=1).detach().cpu().numpy()\n",
    "            \n",
    "            # resize (256 x 256)\n",
    "            temp_mask = []\n",
    "            for img, mask in zip(np.stack(imgs), oms):\n",
    "                transformed = transform(image=img, mask=mask)\n",
    "                mask = transformed['mask']\n",
    "                temp_mask.append(mask)\n",
    "\n",
    "            oms = np.array(temp_mask)\n",
    "            \n",
    "            oms = oms.reshape([oms.shape[0], size*size]).astype(int)\n",
    "            preds_array = np.vstack((preds_array, oms))\n",
    "            \n",
    "            file_name_list.append([i['file_name'] for i in image_infos])\n",
    "    print(\"End prediction.\")\n",
    "    file_names = [y for x in file_name_list for y in x]\n",
    "    \n",
    "    return file_names, preds_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submission.csv 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T19:45:42.235310Z",
     "start_time": "2021-04-16T19:44:30.499016Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = test(model, test_loader, device)\n",
    "\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "submission.to_csv(\"./submission/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "297.278px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
