{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd7fd7c-31c2-417d-b76a-f8fe6e0f94bb",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be40026-fea1-424e-b7de-87219d6e4de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import single_gpu_test\n",
    "from mmcv.runner import load_checkpoint\n",
    "import os\n",
    "from mmcv.parallel import MMDataParallel\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pycocotools.coco import COCO \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a725c347-6ef7-435c-812f-56bee142453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aff906c-bc89-46a5-8a51-f10447347999",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = [\n",
    "    (204,24,30),\n",
    "    (39,147,232),\n",
    "    (85,153,0),\n",
    "    (102,102,102),\n",
    "    (27,133,184),\n",
    "    (90,82,85),\n",
    "    (85,158,131),\n",
    "    (174,90,65),\n",
    "    (195,203,113),\n",
    "    (243,119,54),\n",
    "    (184,167,234)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885adffe-3ff8-44b6-b522-403d46cf64a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"UNKNOWN\", \"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\", \n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
    "\n",
    "model_name = 'vfnet_r2_101_fpn_mdconv_c3-c5_mstrain_2x_coco'\n",
    "folder_name = 'vfnet'\n",
    "\n",
    "# config file 들고오기\n",
    "cfg = Config.fromfile(f'./configs/{folder_name}/{model_name}.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7f4218-6a94-4946-a740-c059c9698493",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = '../input/data/'\n",
    "\n",
    "\n",
    "# dataset 바꾸기\n",
    "cfg.data.train.classes = classes\n",
    "cfg.data.train.img_prefix = PREFIX\n",
    "cfg.data.train.ann_file = PREFIX + 'train.json'\n",
    "# cfg.data.train.pipeline[2]['img_scale'] = (512, 512)\n",
    "\n",
    "cfg.data.val.classes = classes\n",
    "cfg.data.val.img_prefix = PREFIX\n",
    "cfg.data.val.ann_file = PREFIX + 'val.json'\n",
    "# cfg.data.val.pipeline[1]['img_scale'] = (512, 512)\n",
    "\n",
    "cfg.data.test.classes = classes\n",
    "cfg.data.test.img_prefix = PREFIX\n",
    "cfg.data.test.ann_file = PREFIX + 'test.json'\n",
    "# cfg.data.test.pipeline[1]['img_scale'] = (512, 512)\n",
    "\n",
    "\n",
    "cfg.seed=0\n",
    "cfg.gpu_ids = [0]\n",
    "cfg.work_dir = f'./work_dirs/{model_name}'\n",
    "\n",
    "cfg.model.bbox_head.num_classes = 11\n",
    "\n",
    "cfg.optimizer_config.grad_clip = dict(max_norm=35, norm_type=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01bdc2a-b9e2-4dca-a197-4130bb2db5b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(cfg.work_dir, f'epoch_1.pth') # 모델 save path \n",
    "\n",
    "dataset = build_dataset(cfg.data.val)\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        samples_per_gpu=1,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "\n",
    "model = build_detector(cfg.model, test_cfg=cfg.get('test_cfg'))\n",
    "checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n",
    "model.CLASSES = dataset.CLASSES\n",
    "model = MMDataParallel(model.cuda(), device_ids=[0])\n",
    "# model.eval()\n",
    "# model(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881d31c0-d630-4ecc-9fb0-14f89a6164dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = single_gpu_test(model, data_loader, show_score_thr=0.05)\n",
    "# output = [i[0] for i in output] # htc 같이 하나의 이미지에 예측 마스크 까지 던저준다면 실행하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0501ee4-bb72-4a98-ad6e-da524e6f6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Felzenszwalb et al\n",
    "def non_max_suppression_fast(boxes, scores, iou_threshold):\n",
    "    \n",
    "    '''\n",
    "        boxes : coordinates of each box\n",
    "        scores : score of each box\n",
    "        iou_threshold : iou threshold(box with iou larger than threshold will be removed)\n",
    "    '''\n",
    "    \n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    # Init the picked box info\n",
    "    pick = []\n",
    "\n",
    "    # Box coordinate consist of left top and right bottom\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "\n",
    "    # Compute area of each boxes\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    # Greedily select the order of box to compare iou\n",
    "    idxs = np.argsort(scores)\n",
    "\n",
    "    while(len(idxs) > 0):\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        # With vector implementation, we can calculate fast\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        intersection = w * h\n",
    "\n",
    "        # Calculate the iou\n",
    "        iou = intersection / (area[idxs[:last]] + area[idxs[last]] - intersection)\n",
    "\n",
    "        idxs = np.delete(idxs, np.concatenate(([last], np.where(iou > iou_threshold)[0])))\n",
    "\n",
    "    return boxes[pick].astype(\"int\")\n",
    "\n",
    "\n",
    "def draw_result(idx):\n",
    "    out = output[idx]\n",
    "    coco = COCO(annotation_file='../input/data/val.json')\n",
    "    data_dir = '../input/data/'\n",
    "    idx = coco.getImgIds(idx)\n",
    "    img = cv2.imread(data_dir+coco.load_imgs(idx)[0]['file_name'])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    pred_img = img.copy()\n",
    "\n",
    "    anns = coco.load_anns(coco.get_ann_ids(idx))\n",
    "    for ann in anns:\n",
    "        cls_id = ann['category_id']\n",
    "        x,y,w,h = [int(i) for i in ann['bbox']]\n",
    "        img = cv2.rectangle(img, (x,y), (x+w, y+h), COLORS[cls_id], 3)\n",
    "        text = coco.cats[cls_id]['name']\n",
    "        cv2.putText(img, text, (x+10,y+19), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0,0,0))\n",
    "\n",
    "    for c,bboxes in enumerate(out):\n",
    "#         bboxes = non_max_suppression_fast(bboxes[:,:4], bboxes[:,-1], 0.00000000007)\n",
    "        for bbox in bboxes:\n",
    "#             print(bbox)\n",
    "            x1,y1,x2,y2 = bbox[:-1].astype('int64')\n",
    "            score = str(bbox[-1])[:5]\n",
    "#             score = ''\n",
    "            pred_img = cv2.rectangle(pred_img, (x1,y1), (x2,y2), COLORS[c], 3 )\n",
    "            text = coco.cats[c]['name'] + \":\" + score\n",
    "            cv2.putText(pred_img, text, (x1,y1), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0,0,0))\n",
    "            print(text)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1,ncols=2, figsize=(20,20))\n",
    "    ax[0].imshow(img)\n",
    "    ax[1].imshow(pred_img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6847695-7609-432a-bf2f-4c740cb47dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_result(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31283044-cbfc-49e2-bdcd-58f58d333fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_result(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca03af7-8308-4cb8-ae07-d962b4cd38dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_result(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9b0eff-f15f-42be-a45e-830ef83f1d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.train_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e99ba84-9a70-4e9f-9c97-eb14d1f55795",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_loader:\n",
    "    a = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12cb6d-94d6-4f42-8c85-9f07b5c32cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e160f2-b6e7-4d20-8365-9577e52b347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "for i in range(10):\n",
    "    image_id = coco.getImgIds(imgIds=i)\n",
    "    image_infos = coco.loadImgs(image_id)[0]\n",
    "    img = cv2.imread(os.path.join(\"/opt/ml/input/data\", image_infos[\"file_name\"]))\n",
    "    png_name = image_infos[\"file_name\"].replace(\"jpg\", \"png\")\n",
    "    annIds = coco.getAnnIds(imgIds=image_infos[\"id\"])\n",
    "    annList = coco.loadAnns(annIds)\n",
    "    mask = np.ones((img.shape[:2]))\n",
    "    mask *= 255\n",
    "    for i, ann in enumerate(annList):\n",
    "        anmask = coco.annToMask(ann)\n",
    "        anmask = np.int_(anmask)\n",
    "        category_id = ann['category_id']\n",
    "        anmask *= (category_id - (255))\n",
    "        mask += anmask\n",
    "        png_img = Image.fromarray(np.uint8(mask), \"L\")\n",
    "    \n",
    "#     img.close()\n",
    "\n",
    "    png_img.save(os.path.join(\"/opt/ml/input/data/seg_img\", png_name), \"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18423d7-97ef-4e7b-9550-2f08e25705df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imread('../../input/data/seg_img/batch_01_vt/0002.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0627158d-b81f-4cf3-8fef-1d6e7e5379cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74a9ccf-a0e8-4fb8-b2c6-66d645688fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco.annToMask(ann['segmentation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ac29c2-1898-45d4-b0bb-6507b99c6094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "f_lst = glob.glob('../../input/data/seg_img_coco/*')\n",
    "res = np.array([])\n",
    "for f in f_lst:\n",
    "    res = np.append(res, (np.unique(cv2.imread(f))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb96117b-dff5-4c27-9250-8b660a061674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open( '../stuff_val2017.json' , 'r') as f:\n",
    "    a = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e2d9ee-947d-405a-8ce7-55bbd254b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a['annotations'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
