{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24ca332b-8d87-48a0-9d5e-0661c121c176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from Trainer import Trainer\n",
    "from build import Model, Criterion, Optimizer, Scheduler, Transform\n",
    "from utils import fix_random_seed\n",
    "\n",
    "import neptune.new as neptune\n",
    "import neptune_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f79978e9-8555-400f-a385-0a574b4be77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "\n",
    "transform2tensor = ToTensorV2()\n",
    "\n",
    "category_names = [\n",
    "    \"Background\",\n",
    "    \"UNKNOWN\",\n",
    "    \"General trash\",\n",
    "    \"Paper\",\n",
    "    \"Paper pack\",\n",
    "    \"Metal\",\n",
    "    \"Glass\",\n",
    "    \"Plastic\",\n",
    "    \"Styrofoam\",\n",
    "    \"Plastic bag\",\n",
    "    \"Battery\",\n",
    "    \"Clothing\",\n",
    "]\n",
    "\n",
    "\n",
    "class CocoDataset(Dataset):\n",
    "    def __init__(self, json_path, data_path, input_size=(512, 512), norm_mean=(0, 0, 0), norm_std=(1, 1, 1), mode=\"train\", transform=None):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.normalizer = A.Compose([A.Normalize(mean=norm_mean, std=norm_std, always_apply=True)])\n",
    "        self.resizer = A.Compose([A.Resize(*input_size, interpolation=cv2.INTER_AREA, always_apply=True)])\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "        self.coco = COCO(json_path)\n",
    "        self.data_path = data_path\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, tuple) or isinstance(idx, slice):\n",
    "            if isinstance(idx, slice):\n",
    "                idx = range(*idx.indices)\n",
    "\n",
    "            if self.mode in [\"train\", \"valid\"]:\n",
    "                images, masks, image_infos = [], [], []\n",
    "                for i in idx:\n",
    "                    image, mask, image_info = self.__getitem__(i)\n",
    "                    images.append(image)\n",
    "                    masks.append(mask)\n",
    "                    image_infos.append(image_info)\n",
    "                \n",
    "                return images, masks, image_infos\n",
    "                \n",
    "            if self.mode == \"test\":\n",
    "                images, image_infos = [], []\n",
    "                for i in idx:\n",
    "                    image, image_info = self.__getitem__(i)\n",
    "                    images.append(image)\n",
    "                    image_infos.append(image_info)\n",
    "                \n",
    "                return images, image_infos\n",
    "            \n",
    "\n",
    "        image_id = self.coco.getImgIds(imgIds=idx)\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "\n",
    "        image = cv2.imread(os.path.join(self.data_path, image_infos[\"file_name\"]))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.mode in [\"train\", \"valid\"]:\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos[\"id\"])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            mask = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            for ann in anns:\n",
    "                class_name = get_classname(ann[\"category_id\"], cats)\n",
    "                pixel_value = category_names.index(class_name)\n",
    "                mask = np.maximum(self.coco.annToMask(ann) * pixel_value, mask)\n",
    "\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=image, mask=mask)\n",
    "                image = transformed[\"image\"]\n",
    "                mask = transformed[\"mask\"]\n",
    "\n",
    "            # Resize to input size.\n",
    "            if (*image.shape[:2],) != (*self.input_size,):\n",
    "                transformed = self.resizer(image=image, mask=mask)\n",
    "                image = transformed[\"image\"]\n",
    "                mask = transformed[\"mask\"]\n",
    "\n",
    "            # Normalize image.\n",
    "            transformed = self.normalizer(image=image, mask=mask)\n",
    "            image = transformed[\"image\"]\n",
    "            mask = transformed[\"mask\"]\n",
    "\n",
    "            image = image.astype(np.float32)\n",
    "            mask = mask.astype(np.long)\n",
    "\n",
    "            # Convert to tensor.\n",
    "            transformed = transform2tensor(image=image, mask=mask)\n",
    "            image = transformed[\"image\"]\n",
    "            mask = transformed[\"mask\"]\n",
    "\n",
    "            return image, mask, image_infos\n",
    "\n",
    "        if self.mode == \"test\":\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=image)\n",
    "                image = transformed[\"image\"]\n",
    "\n",
    "            # Resize to input size.\n",
    "            if (*image.shape[:2],) != (*self.input_size,):\n",
    "                transformed = self.resizer(image=image)\n",
    "                image = transformed[\"image\"]\n",
    "\n",
    "            # Normalize image.\n",
    "            transformed = self.normalizer(image=image)\n",
    "            image = transformed[\"image\"]\n",
    "\n",
    "            # Convert to tensor.\n",
    "            transformed = transform2tensor(image=image)\n",
    "            image = transformed[\"image\"]\n",
    "\n",
    "            return image, image_infos\n",
    "\n",
    "        raise Exception(\"Mode argument must be one of [train, valid, test].\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coco.getImgIds())\n",
    "\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for cat in cats:\n",
    "        if cat[\"id\"] == classID:\n",
    "            return cat[\"name\"]\n",
    "    return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adf8fa5e-0aaa-463a-aa4a-c93660e83e77",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONFIGS = {\n",
    "    # Model configs.\n",
    "    \"MODEL_NAME\": \"HRNet\",\n",
    "    \"MODEL_PARAMS\": {\n",
    "        \"cfg_path\": \"code/builder/seg_hrnet_w48_520x520_ohem_sgd_lr1e-3_wd1e-4_bs_16_epoch110.yaml\",\n",
    "        \"pth_path\": \"code/builder/seg_hrnet_w48_520x520_ohem_sgd_lr1e-3_wd1e-4_bs_16_epoch110.pth\",\n",
    "        \"classes\": 12\n",
    "    },\n",
    "    # Criterion configs.\n",
    "    \"CRITERION_NAME\": \"CrossEntropyLoss\",\n",
    "    \"CRITERION_PARAMS\": {},\n",
    "    # Optimizer configs.\n",
    "    \"OPTIMIZER_NAME\": \"AdamP\",\n",
    "    \"OPTIMIZER_PARAMS\": {},\n",
    "    # Scheduler configs.\n",
    "    \"SCHEDULER_NAME\": \"MultiStepLR\",\n",
    "    \"SCHEDULER_PARAMS\": {\"milestones\": [5, 10, 15, 20, 25], \"gamma\": 0.4},\n",
    "    \"SCHEDULER_STEP_TYPE\": \"epoch\",\n",
    "    # Data configs.\n",
    "    \"INPUT_SIZE\": (256, 256),\n",
    "    \"NORM_MEAN\": [0.485, 0.456, 0.406],\n",
    "    \"NORM_STD\": [0.229, 0.224, 0.225],\n",
    "    \"AUGMENTATION\": [\n",
    "    ],\n",
    "    # Training configs.\n",
    "    \"EPOCH_NUM\": 30,\n",
    "    \"BATCH_SIZE\": 32,\n",
    "    \"LEARNING_RATE\": 1e-4,\n",
    "    \"K-FOLD_NUM\": 0,\n",
    "    \"EARLY_STOP_NUM\": 5,\n",
    "    \"EARLY_STOP_TARGET\": \"mIoU\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2b88664-d4ad-4491-98ed-08fe2d4ede1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=5.26s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.92s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "transform = Transform(CONFIGS[\"AUGMENTATION\"])\n",
    "\n",
    "data_path = \"../input/data\"\n",
    "train_json = os.path.join(data_path, \"train.json\")\n",
    "valid_json = os.path.join(data_path, \"valid.json\")\n",
    "# dataset.\n",
    "train_dataset = CocoDataset(\n",
    "    json_path=train_json,\n",
    "    data_path=data_path,\n",
    "    input_size=CONFIGS[\"INPUT_SIZE\"],\n",
    "    norm_mean=CONFIGS[\"NORM_MEAN\"],\n",
    "    norm_std=CONFIGS[\"NORM_STD\"],\n",
    "    mode=\"train\",\n",
    "    transform=transform,\n",
    ")\n",
    "valid_dataset = CocoDataset(\n",
    "    json_path=valid_json,\n",
    "    data_path=data_path,\n",
    "    input_size=CONFIGS[\"INPUT_SIZE\"],\n",
    "    norm_mean=CONFIGS[\"NORM_MEAN\"],\n",
    "    norm_std=CONFIGS[\"NORM_STD\"],\n",
    "    mode=\"valid\",\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "090e3263-1acb-4512-913c-b75a3426c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=True, num_workers=4, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04f394da-c14e-478c-ab80-f733284c9899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for images, masks, _ in train_loader:\n",
    "    print(torch.stack(images).shape)\n",
    "    print(torch.stack(masks).shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9ea2f85-94ba-4dd3-9fb2-6aafd6c8f156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[[ 0.1083,  0.1254,  0.1254,  ..., -0.0116, -0.0287,  0.0056],\n",
       "           [ 0.0912,  0.1254,  0.1426,  ..., -0.0116, -0.0458, -0.0116],\n",
       "           [ 0.1426,  0.1083,  0.1254,  ..., -0.0116, -0.0116,  0.0056],\n",
       "           ...,\n",
       "           [ 0.4679,  0.4679,  0.4679,  ..., -0.3027, -0.3198, -0.3369],\n",
       "           [ 0.4851,  0.4679,  0.4508,  ..., -0.3198, -0.3541, -0.3712],\n",
       "           [ 0.5022,  0.5193,  0.5022,  ..., -0.3369, -0.3883, -0.3883]],\n",
       "  \n",
       "          [[-0.1625, -0.1450, -0.1450,  ..., -0.2675, -0.2675, -0.2150],\n",
       "           [-0.1800, -0.1450, -0.1275,  ..., -0.2675, -0.2850, -0.2325],\n",
       "           [-0.1275, -0.1625, -0.1450,  ..., -0.2675, -0.2675, -0.2500],\n",
       "           ...,\n",
       "           [-0.0224, -0.0224, -0.0224,  ..., -0.9503, -0.9678, -0.9853],\n",
       "           [-0.0049, -0.0224, -0.0399,  ..., -0.9678, -1.0028, -1.0203],\n",
       "           [ 0.0126,  0.0301,  0.0126,  ..., -0.9853, -1.0378, -1.0378]],\n",
       "  \n",
       "          [[-0.2532, -0.2358, -0.2358,  ..., -0.4101, -0.4101, -0.4101],\n",
       "           [-0.2707, -0.2358, -0.2184,  ..., -0.4101, -0.4275, -0.4275],\n",
       "           [-0.2184, -0.2532, -0.2358,  ..., -0.4101, -0.4101, -0.4275],\n",
       "           ...,\n",
       "           [-0.2532, -0.2532, -0.2532,  ..., -1.3687, -1.3861, -1.4036],\n",
       "           [-0.2358, -0.2532, -0.2707,  ..., -1.3861, -1.4210, -1.4384],\n",
       "           [-0.2184, -0.2010, -0.2184,  ..., -1.4036, -1.4559, -1.4559]]]),\n",
       "  tensor([[[ 0.0569,  0.0569,  0.0741,  ...,  0.1597,  0.1254,  0.1426],\n",
       "           [ 0.0398,  0.0741,  0.1083,  ...,  0.0912,  0.0912,  0.1254],\n",
       "           [ 0.1426,  0.1254,  0.1254,  ...,  0.1426,  0.1597,  0.1254],\n",
       "           ...,\n",
       "           [ 0.3994,  0.3823,  0.3138,  ...,  0.5536,  0.5536,  0.6049],\n",
       "           [ 0.3309,  0.3823,  0.3481,  ...,  0.6049,  0.5878,  0.6049],\n",
       "           [ 0.3994,  0.3994,  0.3481,  ...,  0.5707,  0.5878,  0.6221]],\n",
       "  \n",
       "          [[-0.5126, -0.5126, -0.5126,  ..., -0.3025, -0.3375, -0.3200],\n",
       "           [-0.4951, -0.5126, -0.4776,  ..., -0.3725, -0.3725, -0.3375],\n",
       "           [-0.3901, -0.4076, -0.4076,  ..., -0.3200, -0.3025, -0.3375],\n",
       "           ...,\n",
       "           [-0.0924, -0.1099, -0.1800,  ...,  0.1176,  0.1176,  0.1702],\n",
       "           [-0.1625, -0.1099, -0.1450,  ...,  0.1702,  0.1527,  0.1877],\n",
       "           [-0.0924, -0.0924, -0.1450,  ...,  0.1352,  0.1527,  0.2052]],\n",
       "  \n",
       "          [[-0.7238, -0.7238, -0.6715,  ..., -0.5670, -0.6018, -0.5844],\n",
       "           [-0.6715, -0.6715, -0.6367,  ..., -0.6367, -0.6367, -0.6018],\n",
       "           [-0.5670, -0.5844, -0.5844,  ..., -0.5844, -0.5670, -0.6018],\n",
       "           ...,\n",
       "           [-0.3230, -0.3404, -0.4101,  ..., -0.2184, -0.2532, -0.2532],\n",
       "           [-0.3927, -0.3404, -0.3753,  ..., -0.1835, -0.2358, -0.2532],\n",
       "           [-0.3230, -0.3230, -0.3753,  ..., -0.2184, -0.2532, -0.2358]]]),\n",
       "  tensor([[[-1.2274, -1.9638, -0.9192,  ...,  0.5878,  0.6049,  0.3652],\n",
       "           [-0.6965, -1.7412, -0.2171,  ...,  0.6392,  0.2967,  0.1597],\n",
       "           [-1.7754, -1.5699, -0.9363,  ...,  0.6392,  0.6563, -0.1657],\n",
       "           ...,\n",
       "           [ 0.5364, -0.1657,  0.1597,  ...,  0.1083, -1.2959, -1.6898],\n",
       "           [ 0.4337, -0.5767, -0.1486,  ...,  0.9988,  1.2385, -0.7822],\n",
       "           [ 0.7419, -0.4739, -0.3198,  ...,  0.6049,  1.0673, -0.0116]],\n",
       "  \n",
       "          [[-0.6352, -1.4055, -0.2850,  ...,  1.1856,  1.3431,  1.2031],\n",
       "           [-0.3725, -1.3704,  0.1877,  ...,  1.4832,  1.2906,  1.2381],\n",
       "           [-1.5630, -1.3179, -0.6352,  ...,  1.6933,  1.8333,  1.0630],\n",
       "           ...,\n",
       "           [ 1.3782,  0.7479,  1.1681,  ...,  0.6254, -1.0203, -1.3529],\n",
       "           [ 1.4132,  0.5203,  1.0805,  ...,  1.7108,  1.8333, -0.3025],\n",
       "           [ 1.6232,  0.5728,  0.8880,  ...,  1.3957,  1.7283,  0.5553]],\n",
       "  \n",
       "          [[ 0.2173, -0.6018,  0.4614,  ...,  1.9254,  2.0997,  1.9080],\n",
       "           [ 0.3393, -0.7064,  0.7925,  ...,  2.0823,  1.8905,  1.9254],\n",
       "           [-0.9156, -0.6890, -0.0267,  ...,  2.2566,  2.4308,  1.8208],\n",
       "           ...,\n",
       "           [ 2.0648,  1.4548,  1.9080,  ...,  1.2805, -0.3578, -0.5670],\n",
       "           [ 2.1171,  1.2805,  1.8731,  ...,  2.3437,  2.4831,  0.4788],\n",
       "           [ 2.4134,  1.3677,  1.7337,  ...,  2.0648,  2.3786,  1.3328]]]),\n",
       "  tensor([[[ 0.1768,  0.8618,  0.7933,  ...,  0.9132,  0.9132,  0.9646],\n",
       "           [ 0.1597,  0.0741,  1.1187,  ...,  0.8447,  0.9303,  0.4166],\n",
       "           [ 0.3823,  0.2624,  0.5022,  ...,  0.5878,  0.5536,  0.2624],\n",
       "           ...,\n",
       "           [ 0.6392, -0.0116,  1.1358,  ..., -0.0629,  1.0331,  0.8276],\n",
       "           [ 0.1768,  0.7762,  1.3413,  ...,  0.7762,  0.7591,  0.4851],\n",
       "           [ 0.1083,  0.5878,  0.5193,  ...,  2.2318,  1.7180, -0.2856]],\n",
       "  \n",
       "          [[ 0.2227,  0.9230,  0.8529,  ...,  0.8880,  0.8880,  0.8880],\n",
       "           [ 0.2052,  0.1176,  1.1856,  ...,  0.8179,  0.9055,  0.3803],\n",
       "           [ 0.4328,  0.3102,  0.5553,  ...,  0.5553,  0.5203,  0.2227],\n",
       "           ...,\n",
       "           [ 0.6779,  0.0301,  1.2031,  ..., -0.0049,  1.1155,  0.8880],\n",
       "           [ 0.2052,  0.8354,  1.3606,  ...,  0.9055,  0.8354,  0.5378],\n",
       "           [ 0.1352,  0.5903,  0.5203,  ...,  2.3936,  1.8333, -0.2675]],\n",
       "  \n",
       "          [[ 0.3742,  1.0714,  1.0191,  ...,  0.9494,  0.9319,  0.9494],\n",
       "           [ 0.3568,  0.2696,  1.3502,  ...,  0.8797,  0.9494,  0.4265],\n",
       "           [ 0.6008,  0.4788,  0.7228,  ...,  0.6182,  0.5834,  0.2871],\n",
       "           ...,\n",
       "           [ 0.8971,  0.1999,  1.3328,  ...,  0.1999,  1.2805,  1.0539],\n",
       "           [ 0.4265,  1.0017,  1.5071,  ...,  1.1237,  1.0365,  0.7228],\n",
       "           [ 0.3568,  0.7751,  0.6879,  ...,  2.6226,  2.0648, -0.0441]]])],\n",
       " [tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]),\n",
       "  tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]),\n",
       "  tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]),\n",
       "  tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]])],\n",
       " [{'license': 0,\n",
       "   'url': None,\n",
       "   'file_name': 'batch_01_vt/0003.jpg',\n",
       "   'height': 512,\n",
       "   'width': 512,\n",
       "   'date_captured': None,\n",
       "   'id': 0},\n",
       "  {'license': 0,\n",
       "   'url': None,\n",
       "   'file_name': 'batch_01_vt/0005.jpg',\n",
       "   'height': 512,\n",
       "   'width': 512,\n",
       "   'date_captured': None,\n",
       "   'id': 1},\n",
       "  {'license': 0,\n",
       "   'url': None,\n",
       "   'file_name': 'batch_01_vt/0006.jpg',\n",
       "   'height': 512,\n",
       "   'width': 512,\n",
       "   'date_captured': None,\n",
       "   'id': 2},\n",
       "  {'license': 0,\n",
       "   'url': None,\n",
       "   'file_name': 'batch_01_vt/0007.jpg',\n",
       "   'height': 512,\n",
       "   'width': 512,\n",
       "   'date_captured': None,\n",
       "   'id': 3}])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "126fcbf7-8bd6-47e8-96c8-0ed61952d2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1083,  0.1254,  0.1254,  ..., -0.0116, -0.0287,  0.0056],\n",
       "          [ 0.0912,  0.1254,  0.1426,  ..., -0.0116, -0.0458, -0.0116],\n",
       "          [ 0.1426,  0.1083,  0.1254,  ..., -0.0116, -0.0116,  0.0056],\n",
       "          ...,\n",
       "          [ 0.4679,  0.4679,  0.4679,  ..., -0.3027, -0.3198, -0.3369],\n",
       "          [ 0.4851,  0.4679,  0.4508,  ..., -0.3198, -0.3541, -0.3712],\n",
       "          [ 0.5022,  0.5193,  0.5022,  ..., -0.3369, -0.3883, -0.3883]],\n",
       " \n",
       "         [[-0.1625, -0.1450, -0.1450,  ..., -0.2675, -0.2675, -0.2150],\n",
       "          [-0.1800, -0.1450, -0.1275,  ..., -0.2675, -0.2850, -0.2325],\n",
       "          [-0.1275, -0.1625, -0.1450,  ..., -0.2675, -0.2675, -0.2500],\n",
       "          ...,\n",
       "          [-0.0224, -0.0224, -0.0224,  ..., -0.9503, -0.9678, -0.9853],\n",
       "          [-0.0049, -0.0224, -0.0399,  ..., -0.9678, -1.0028, -1.0203],\n",
       "          [ 0.0126,  0.0301,  0.0126,  ..., -0.9853, -1.0378, -1.0378]],\n",
       " \n",
       "         [[-0.2532, -0.2358, -0.2358,  ..., -0.4101, -0.4101, -0.4101],\n",
       "          [-0.2707, -0.2358, -0.2184,  ..., -0.4101, -0.4275, -0.4275],\n",
       "          [-0.2184, -0.2532, -0.2358,  ..., -0.4101, -0.4101, -0.4275],\n",
       "          ...,\n",
       "          [-0.2532, -0.2532, -0.2532,  ..., -1.3687, -1.3861, -1.4036],\n",
       "          [-0.2358, -0.2532, -0.2707,  ..., -1.3861, -1.4210, -1.4384],\n",
       "          [-0.2184, -0.2010, -0.2184,  ..., -1.4036, -1.4559, -1.4559]]]),\n",
       " tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " {'license': 0,\n",
       "  'url': None,\n",
       "  'file_name': 'batch_01_vt/0003.jpg',\n",
       "  'height': 512,\n",
       "  'width': 512,\n",
       "  'date_captured': None,\n",
       "  'id': 0})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093033c7-31c4-4201-8013-c598563b9d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
